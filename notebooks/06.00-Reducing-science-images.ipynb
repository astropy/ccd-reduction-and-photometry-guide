{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing science images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from astropy import units as u\n",
    "import ccdproc as ccdp\n",
    "\n",
    "from convenience_functions import show_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "[ccdproc](ccdproc.readthedocs.io) provides a couple of ways to approach calibration of the science images:\n",
    "\n",
    "+ Perform each of the individual steps manually using `subtract_bias`, `subtract_dark`, and `flat_correct`.\n",
    "+ Use the [`ccd_process` function]() to perform all of the reduction steps. \n",
    "\n",
    "This notebook will do each of those in separate sections below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_dark_exposure(image, dark_exposure_times, tolerance=0.5):\n",
    "    \"\"\"\n",
    "    Find the nearest exposure time of a dark frame to the exposure time of the image,\n",
    "    raising an error if the difference in exposure time is more than tolerance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    image : astropy.nddata.CCDData\n",
    "        Image for which a matching dark is needed.\n",
    "    \n",
    "    dark_exposure_times : list\n",
    "        Exposure times for which there are darks.\n",
    "    \n",
    "    tolerance : float or ``None``, optional\n",
    "        Maximum difference, in seconds, between the image and the closest dark. Set\n",
    "        to ``None`` to skip the tolerance test.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    float\n",
    "        Closest dark exposure time to the image.\n",
    "    \"\"\"\n",
    "\n",
    "    dark_exposures = np.array(list(dark_exposure_times))\n",
    "    idx = np.argmin(np.abs(dark_exposures - image.header['exptime']))\n",
    "    closest_dark_exposure = dark_exposures[idx]\n",
    "\n",
    "    if (tolerance is not None and \n",
    "        np.abs(image.header['exptime'] - closest_dark_exposure) > tolerance):\n",
    "        \n",
    "        raise RuntimeError('Closest dark exposure time is {} for flat of exposure '\n",
    "                           'time {}.'.format(closest_dark_exposure, a_flat.header['exptime']))\n",
    "        \n",
    "    \n",
    "    return closest_dark_exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_path = Path('example1-reduced')\n",
    "\n",
    "science_imagetyp = 'object'\n",
    "flat_imagetyp = 'flatfield'\n",
    "\n",
    "ifc_reduced = ccdp.ImageFileCollection('example1-reduced')\n",
    "ifc_raw = ccdp.ImageFileCollection('python_imred_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lights = ifc_raw.summary[ifc_raw.summary['imagetyp'] == science_imagetyp.upper()]\n",
    "lights['date-obs', 'file', 'object', 'filter', 'exptime']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_darks = {ccd.header['exptime']: ccd for ccd in ifc_reduced.ccds(imagetyp='dark', combined=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibs = {}\n",
    "for im_type in ['bias', 'dark', flat_imagetyp]:\n",
    "    calibs[im_type] = [ccd for ccd in ifc_reduced.ccds(imagetyp=im_type, combined=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THIS IS BAD NEED TO FIND MATCHING DARK EXPOSURE TIME!! \n",
    "# AND MATCHING FLAT FILTER!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reds = []\n",
    "light_ccds = []\n",
    "for light, file_name in ifc_raw.ccds(imagetyp=science_imagetyp, return_fname=True, ccd_kwargs=dict(unit='adu')):\n",
    "    light_ccds.append(light)\n",
    "    reduced = ccdp.subtract_overscan(light, overscan=light[:, 2055:], median=True)\n",
    "    reduced = ccdp.trim_image(light[:, :2048])\n",
    "    #reduced = ccdp.subtract_bias(reduced, calibs['bias'][0])\n",
    "    closest_dark = find_nearest_dark_exposure(reduced, combined_darks.keys())\n",
    "    reduced = ccdp.subtract_dark(reduced, combined_darks[closest_dark], exposure_time='exptime', exposure_unit=u.second)\n",
    "    good_flat = [c for c in calibs[flat_imagetyp] if c.header['filter'] == light.header['filter']][0]\n",
    "    reduced = ccdp.flat_correct(reduced, good_flat)\n",
    "    all_reds.append(reduced)\n",
    "    reduced.write(reduced_path / file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_light = 1\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "filt = light_ccds[which_light].header['filter']\n",
    "axes[0].set_title('Uncalibrated image {}'.format(filt))\n",
    "show_image(light_ccds[which_light], cmap='gray', ax=axes[0], fig=fig, percl=90)\n",
    "\n",
    "axes[1].set_title('Calibrated image')\n",
    "show_image(all_reds[which_light].data, cmap='gray', ax=axes[1], fig=fig, percl=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_image(combined_darks[300], cmap='gray', percl=80)\n",
    "show_image(calibs['bias'][0], cmap='gray', percl=80)\n",
    "show_image(calibs[flat_imagetyp][0], cmap='gray', percl=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_path = Path('example2-reduced')\n",
    "\n",
    "science_imagetyp = 'light'\n",
    "\n",
    "ifc_reduced = ccdp.ImageFileCollection('example2-reduced')\n",
    "ifc_raw = ccdp.ImageFileCollection('example-thermo-electric')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the light images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lights = ifc_raw.summary[ifc_raw.summary['imagetyp'] == science_imagetyp.upper()]\n",
    "lights['date-obs', 'file', 'object', 'filter', 'exposure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab some calibration frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibs = {}\n",
    "for im_type in ['bias', 'dark', 'flat']:\n",
    "    calibs[im_type] = [ccd for ccd in ifc_reduced.ccds(imagetyp=im_type, combined=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reduce them all...\n",
    "\n",
    "# BUT FIX THE FACT THAT WE ARE NOT MATCHING WE ARE JUST GRABBING THE FIRST ONE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reds = []\n",
    "light_ccds = []\n",
    "for light, file_name in ifc_raw.ccds(imagetyp='light', return_fname=True):\n",
    "    light_ccds.append(light)\n",
    "    reduced = ccdp.trim_image(light[:, :4096])\n",
    "    reduced = ccdp.subtract_bias(reduced, calibs['bias'][0])\n",
    "    reduced = ccdp.subtract_dark(reduced, calibs['dark'][0], exposure_time='exptime', exposure_unit=u.second)\n",
    "    reduced = ccdp.flat_correct(reduced, calibs['flat'][0])\n",
    "    all_reds.append(reduced)\n",
    "    reduced.write(reduced_path / file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_light = 0\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "axes[0].set_title('Uncalibrated image')\n",
    "show_image(light_ccds[which_light], cmap='gray', ax=axes[0], fig=fig, percl=90)\n",
    "\n",
    "axes[1].set_title('Calibrated image')\n",
    "show_image(all_reds[which_light].data, cmap='gray', ax=axes[1], fig=fig, percl=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_light = 1\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "axes[0].set_title('Uncalibrated image')\n",
    "show_image(light_ccds[which_light], cmap='gray', ax=axes[0], fig=fig, percl=90)\n",
    "\n",
    "axes[1].set_title('Calibrated image')\n",
    "show_image(all_reds[which_light].data, cmap='gray', ax=axes[1], fig=fig, percl=90)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
