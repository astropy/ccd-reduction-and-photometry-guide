{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrating the flats\n",
    "\n",
    "Recall that the counts in an astronomical image include dark current, noise and a nearly-constant offset, the bias. The individual flat frames need to have bias and dark removed from them. Depending on the exposure times of the images you have, you may or may not need to subtract dark and bias separately.\n",
    "\n",
    "If the combined dark frame needs to be scaled to a different exposure time then bias and dark must be handled separately; otherwise, the dark and bias can be removed in a single step because dark frames also include bias.\n",
    "\n",
    "The potential reduction steps for flat frames are below:\n",
    "\n",
    "+ Subtract overscan and trim, if necessary\n",
    "+ Subtract bias, if necessary\n",
    "+ Subtract dark current, scaling if necessary (scale down when possible)\n",
    "\n",
    "As in the chapters about bias and dark we will work through two example. In Example 1 the darks are not scaled and the overscan region is used as part of the calibration. In Example 2 the darks are scaled and the overscan region is trimmed off without being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definition \n",
    "\n",
    "The function below finds the nearest dark exposure time to the exposure time of a given image. An exception is raised if the difference in exposure time is larger than `tolerance`, unless `tolerance` is set to `None`. A small numerical tolerance is most useful if you anticipate not scaling the dark frames and finding a dark exposure time close to the time of the image. Disregarding the tolerance is useful if the intent is to scale the dark frames anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest_dark_exposure(image, dark_exposure_times, tolerance=0.5):\n",
    "    \"\"\"\n",
    "    Find the nearest exposure time of a dark frame to the exposure time of the image,\n",
    "    raising an error if the difference in exposure time is more than tolerance.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    image : astropy.nddata.CCDData\n",
    "        Image for which a matching dark is needed.\n",
    "    \n",
    "    dark_exposure_times : list\n",
    "        Exposure times for which there are darks.\n",
    "    \n",
    "    tolerance : float or ``None``, optional\n",
    "        Maximum difference, in seconds, between the image and the closest dark. Set\n",
    "        to ``None`` to skip the tolerance test.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    float\n",
    "        Closest dark exposure time to the image.\n",
    "    \"\"\"\n",
    "\n",
    "    dark_exposures = np.array(list(dark_exposure_times))\n",
    "    idx = np.argmin(np.abs(dark_exposures - image.header['exptime']))\n",
    "    closest_dark_exposure = dark_exposures[idx]\n",
    "\n",
    "    if (tolerance is not None and \n",
    "        np.abs(image.header['exptime'] - closest_dark_exposure) > tolerance):\n",
    "        \n",
    "        raise RuntimeError('Closest dark exposure time is {} for flat of exposure '\n",
    "                           'time {}.'.format(closest_dark_exposure, a_flat.header['exptime']))\n",
    "        \n",
    "    \n",
    "    return closest_dark_exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.nddata import CCDData\n",
    "import ccdproc as ccdp\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from convenience_functions import show_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: no scaling of dark frames\n",
    "\n",
    "The images for this example are from chip 0 of the Large Format Camera at Palomar Observatory. The raw images are at XXX, and this notebook assumes that you have worked through the notebooks on bias and dark so that there is a folder called `example1-reduced` in the same folder as this notebook. \n",
    "\n",
    "We'll go through this example twice: once with a single image to explain each step, then processing all of the flat frames in the directory of raw data.\n",
    "\n",
    "An image collection is defined below, along with a couple of settings useful for this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_path = Path('example1-reduced')\n",
    "\n",
    "ifc_reduced = ccdp.ImageFileCollection(reduced_path)\n",
    "\n",
    "combined_dark_files = ifc_reduced.files_filtered(imagetyp='dark', combined=True)\n",
    "\n",
    "flat_image_type = 'FLATFIELD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data should be in the directory `example-cryo-LFC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = Path('example-cryo-LFC')\n",
    "\n",
    "ifc_raw = ccdp.ImageFileCollection(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below checks that the files needed are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_combined_dark = len(combined_dark_files)\n",
    "expected_exposure_times = set([7, 70, 300])\n",
    "\n",
    "if n_combined_dark < 3:\n",
    "    raise RuntimeError('One or more combined dark is missing. Please re-run the dark notebook.')\n",
    "elif n_combined_dark > 3:\n",
    "    raise RuntimeError('There are more combined dark frames than expected.')\n",
    "    \n",
    "actual_exposure_times = set(h['exptime'] for h in ifc_reduced.headers(imagetyp='dark', combined=True))\n",
    "\n",
    "if (expected_exposure_times - actual_exposure_times):\n",
    "    raise RuntimeError('Encountered unexpected exposure time in combined darks. '\n",
    "                       'The unexpected times are {}'.format(actual_exposure_times - expected_exposure_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get one of the flat frames as a `CCDData` object and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_flat = CCDData.read(ifc_raw.files_filtered(imagetyp='flatfield', include_path=True)[0], unit='adu')\n",
    "\n",
    "show_image(a_flat, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not a lot of variation in this. Note that the overscan region on the right stands out as a black bar, and that there is apparently also an overscan region across the top of the chip. There appears to be a slight variaion in pixel values from the bottom to the top of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract overscan and trim, if necessary\n",
    "\n",
    "The overscan is useful for the LFC and needs to be subtracted and trimmed off. See [this example in the dark reduction notebook](03-05-Calibrate-dark-images.ipynb#Decide-which-calibration--steps-to-take) for a review of the overscan parameters. The overscan region is the Python slice `[:, 2055:]` while the region to be retained after trimming is the Python slice `[:, :2048]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract the overscan\n",
    "a_flat_reduced = ccdp.subtract_overscan(a_flat, overscan=a_flat[:, 2055:], median=True)\n",
    "\n",
    "# Trim the overscan\n",
    "a_flat_reduced = ccdp.trim_image(a_flat_reduced[:, :2048])\n",
    "\n",
    "# Display the result so far\n",
    "show_image(a_flat_reduced, cmap='gray')\n",
    "plt.title('Single flat frame, overscan subtracted and trimmed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming off the overscan makes such a big difference primarily because the image stretch changed; the lowest pixel values are now around 18000 instead of 2000. With that change the non-uniformity across the detector is much clearer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract bias, if necessary\n",
    "\n",
    "For this particular set of images there are darks with exposure time 7, 70 and 300 sec. The flat images have the exposure times listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ifc_raw.summary['exptime'][ifc_raw.summary['imagetyp'] == 'FLATFIELD'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are close enough to the exposure time of the dark frames that there is no need to scale the darks by exposure time. If the darks are not going to be scaled then there is no need to subtract the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract dark current, scaling if necessary (scale down when possible)\n",
    "\n",
    "We need to subtract the dark without scaling it. Rather than manually figuring out which dark to subtract we use the dark frame closest in exposure time to the flat, within a tolerance of 1 second to ensure that we do not end up using a dark *too* far off in exposure time from the flat.\n",
    "\n",
    "First, find the dark exposure time closest to the flat. We will need to do this again later in the notebook, so we define a function to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_dark = find_nearest_dark_exposure(a_flat_reduced, actual_exposure_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be convenient to be able to access the darks via a dictionary whose key is the exposure time, so we set that up below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_darks = {ccd.header['exptime']: ccd for ccd in ifc_reduced.ccds(imagetyp='dark', combined=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we subtract the dark from the flat and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_flat_reduced = ccdp.subtract_dark(a_flat_reduced, combined_darks[closest_dark], \n",
    "                                    exposure_time='exptime', exposure_unit=u.second, scale=False)\n",
    "show_image(a_flat_reduced, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much change here; that is not surprising since the dark current in this camera is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrated all of the flats in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below calibrates each of the flats in the folder, automatically grabbing the correct combined dark for each flat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ccd, file_name in ifc_raw.ccds(imagetyp='FLATFIELD',            # Just get the bias frames\n",
    "                                         ccd_kwargs={'unit': 'adu'}, # CCDData requires a unit for the image if \n",
    "                                                                     # it is not in the header\n",
    "                                         return_fname=True           # Provide the file name too.\n",
    "                                        ):    \n",
    "    # Subtract the overscan\n",
    "    ccd = ccdp.subtract_overscan(ccd, overscan=ccd[:, 2055:], median=True)\n",
    "    \n",
    "    # Trim the overscan\n",
    "    ccd = ccdp.trim_image(ccd[:, :2048])\n",
    "    \n",
    "    # Find the correct dark exposure\n",
    "    closest_dark = find_nearest_dark_exposure(ccd, actual_exposure_times)\n",
    "    \n",
    "    # Subtract the dark current \n",
    "    ccd = ccdp.subtract_dark(ccd, combined_darks[closest_dark],\n",
    "                             exposure_time='exptime', exposure_unit=u.second)\n",
    "\n",
    "    # Save the result; there are some duplicate file names so pre-pend \"flat\"\n",
    "    ccd.write(reduced_path / ('flat-' + file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Dark frames are scaled\n",
    "\n",
    "The images in this example, like in the previous notebooks, is a thermo-electrically cooled CCD described in more detail in the [overscan notebook](01-08-Overscan.ipynb#Case-2:-Thermo-electrically-cooled-Apogee-Aspen-CG16M). \n",
    "\n",
    "We'll go through this example twice: once with a single image to explain each step, then processing all of the flat frames in the directory of raw data.\n",
    "\n",
    "An image collection is defined below, along with a couple of settings useful for this example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_path = Path('example2-reduced')\n",
    "\n",
    "ifc_reduced = ccdp.ImageFileCollection(reduced_path)\n",
    "\n",
    "combined_dark_files = ifc_reduced.files_filtered(imagetyp='dark', combined=True)\n",
    "\n",
    "flat_image_type = 'FLAT'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The raw data should be in the directory `example-thermo-electric`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = Path('example-thermo-electric')\n",
    "\n",
    "ifc_raw = ccdp.ImageFileCollection(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below checks that the files needed are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_combined_dark = len(combined_dark_files)\n",
    "\n",
    "n_dark_expected = 1\n",
    "expected_exposure_times = set([90])\n",
    "\n",
    "if n_combined_dark < n_dark_expected:\n",
    "    raise RuntimeError('One or more combined dark is missing. Please re-run the dark notebook.')\n",
    "elif n_combined_dark > n_dark_expected:\n",
    "    raise RuntimeError('There are more combined dark frames than expected.')\n",
    "    \n",
    "actual_exposure_times = set(h['exptime'] for h in ifc_reduced.headers(imagetyp='dark', combined=True))\n",
    "\n",
    "if (expected_exposure_times - actual_exposure_times):\n",
    "    raise RuntimeError('Encountered unexpected exposure time in combined darks. '\n",
    "                       'The unexpected times are {}'.format(actual_exposure_times - expected_exposure_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, get one of the flat frames as a `CCDData` object and display it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_flat = CCDData.read(ifc_raw.files_filtered(imagetyp='flat', include_path=True)[0], unit='adu')\n",
    "\n",
    "show_image(a_flat, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a much different pattern of variation across the sensor in this case than in Example 1. The multiple \"donuts\" in the image are pieces of dust and there is significant vignetting (darkening) in the top and bottom corners of the image on the right side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract overscan and trim: only trim for this camera\n",
    "\n",
    "The overscan is not useful for this camera. The region to be retained after trimming is the Python slice `[:, :4096]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim the overscan\n",
    "a_flat_reduced = ccdp.trim_image(a_flat[:, :4096])\n",
    "\n",
    "# Display the result so far\n",
    "show_image(a_flat_reduced, cmap='gray')\n",
    "plt.title('Single flat frame, overscan trimmed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trimming off the overscan did not make a big difference primarily because the overscan region of this camera is not useful. A useful overscan would have had values around the bias level for this camera, about 1200 counts. The image stretch did change a bit; prior to trimming the lower end of the color scale was 38000 and now it is 40000. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract bias, if necessary\n",
    "\n",
    "For this particular set of images there is a combined dark with exposure time 90 sec. The flat images have the exposure times listed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ifc_raw.summary['exptime'][ifc_raw.summary['imagetyp'] == 'FLAT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are quite different than the exposure time of the dark frames so the dark will need to be scaled by exposure time, which means that the bias has been removed from the combined dark.\n",
    "\n",
    "Because of that, the bias needs to be removed the flat before subtracting the dark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_bias = list(ifc_reduced.ccds(combined=True, imagetyp='bias'))[0]\n",
    "a_flat_reduced = ccdp.subtract_bias(a_flat_reduced, combined_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the result so far\n",
    "show_image(a_flat_reduced, cmap='gray')\n",
    "plt.title('Single flat frame, overscan trimmed and bias subtracted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except for a change in the image scale shown on the color bar there isn't much visually different after subtracting the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract dark current, scaling if necessary (scale down when possible)\n",
    "\n",
    "Here we will need to scale the dark from the 90 sec exposure time of the dark frame to the exposure time of each flat image. The [ccdproc function `subtract_dark`]() provides keywords for doing this scaling automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_dark = find_nearest_dark_exposure(a_flat_reduced, actual_exposure_times, tolerance=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be convenient to be able to access the darks via a dictionary whose key is the exposure time, so we set that up below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_darks = {ccd.header['exptime']: ccd for ccd in ifc_reduced.ccds(imagetyp='dark', combined=True)}\n",
    "combined_darks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we subtract the dark from the flat and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_flat_reduced = ccdp.subtract_dark(a_flat_reduced, combined_darks[closest_dark], \n",
    "                                    exposure_time='exptime', exposure_unit=u.second, scale=True)\n",
    "show_image(a_flat_reduced, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much change here; that is not surprising since the dark current in this camera is low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrated all of the flats in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below calibrates each of the flats in the folder, automatically grabbing the correct combined dark for each flat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ccd, file_name in ifc_raw.ccds(imagetyp='FLAT',            # Just get the bias frames\n",
    "                                   return_fname=True           # Provide the file name too.\n",
    "                                  ):\n",
    "        \n",
    "    # Trim the overscan\n",
    "    ccd = ccdp.trim_image(ccd[:, :4096])\n",
    "    \n",
    "    # Find the correct dark exposure\n",
    "    closest_dark = find_nearest_dark_exposure(ccd, actual_exposure_times, tolerance=100)\n",
    "    \n",
    "    # Subtract the dark current \n",
    "    ccd = ccdp.subtract_dark(ccd, combined_darks[closest_dark],\n",
    "                             exposure_time='exptime', exposure_unit=u.second, scale=True)\n",
    "\n",
    "    # Save the result\n",
    "    ccd.write(reduced_path / file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
