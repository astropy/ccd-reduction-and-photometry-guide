{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image segmentation with a simulated image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we begin with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from astropy.convolution import convolve\n",
    "from astropy.stats import sigma_clipped_stats, gaussian_sigma_to_fwhm\n",
    "from astropy.table import QTable\n",
    "from astropy.visualization import simple_norm, SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from photutils.aperture import CircularAperture, EllipticalAperture\n",
    "from photutils.centroids import centroid_2dg\n",
    "from photutils.datasets import make_100gaussians_image, make_gaussian_sources_image, make_noise_image\n",
    "from photutils.detection import find_peaks, DAOStarFinder\n",
    "from photutils.segmentation import detect_sources, make_2dgaussian_kernel, SourceCatalog\n",
    "from photutils.utils import make_random_cmap\n",
    "\n",
    "plt.style.use('../photutils_notebook_style.mplstyle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More about image segmentation using a small example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before diving into an applicatino of image segmentation to a simulated image, some more description of the technique may be helpful. We contruct a small imge 10 pixels on a side. We will start with some noise and add set the value in several pixels well above the standard deviation of the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the noise\n",
    "std_dev = 5\n",
    "image = make_noise_image([10, 10], stddev=std_dev, mean=0)\n",
    "\n",
    "# Make a source smaller than the image\n",
    "source = np.array(\n",
    "    [\n",
    "        [1, 2, 3, 1],\n",
    "        [1, 0.5, 2, 3],\n",
    "        [1, 3, 2, 1],\n",
    "        [0, 2, 1, 0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Make sure the source pixels are much larger than the background\n",
    "source = 10.0 * std_dev * source\n",
    "\n",
    "# Put one source in the upper left...\n",
    "image[1:5, 0:4] += source\n",
    "# ...and one source in the lower right, and transpose it to make it look different\n",
    "image[-5:-1, -4:] += source.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(image, cmap=\"viridis\")\n",
    "\n",
    "plt.title(\"Simulated image\")\n",
    "# Suppress tick labels\n",
    "plt.xticks([])\n",
    "plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a detection image, called `detected_image` below, in which all pixels with value larger than 3 times the standard deviation are set to one, and the rest set to zero. In this example, the detect pixels fall into one of two connected groups, by construction.\n",
    "\n",
    "This detection is shown below, with the pixels in the two sources labeled by either \"1\" or \"2\" and the rest of the pixels labeled \"0\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_pixels = image > 3 * std_dev\n",
    "detected_image = image.copy()\n",
    "detected_image[~source_pixels] = 0\n",
    "# This intiially labels all sources with the same number, 1\n",
    "detected_image[source_pixels] = 1 \n",
    "\n",
    "# The sources were added in a way that makes it easy to separate the sources,\n",
    "# so number the source in the lower right 2\n",
    "detected_image[5:, 5:] *= 2\n",
    "\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(detected_image, cmap=\"viridis\")\n",
    "\n",
    "for x in range(10):\n",
    "    for y in range(10):\n",
    "        plt.annotate(f\"{detected_image[y, x]:.0f}\", (x, y), va=\"center\", ha=\"center\", color=\"cyan\")\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.title(\"Segmentation image\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That, in a nutshell, is image segmentation. The implementation is more complicated than what is done above, and the image is typically convolved with a filter before doing the segmentation, but the gist of the method is straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image segmentation with a larger image\n",
    "\n",
    "We again consider the simulated image with 100 Gaussian sources that was introduced in [background removal with a simulated image](01.01.01-Background-removal-simulated-data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, let's create the image and subtract the background. Recall that this image contains a mix of star-like object and more extended sources, and the sigma clipped median does a reasonable job of estimating the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_100gaussians_image()\n",
    "mean, med, std = sigma_clipped_stats(data, sigma=3.0, maxiters=5)\n",
    "data_subtracted = data - med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for image segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few settings we need to make before detecting sources with iumage segmentation using the [`photutils`](https://photutils.readthedocs.io/en/stable/) function [`detect_sources`](https://photutils.readthedocs.io/en/stable/api/photutils.segmentation.detect_sources.html#photutils.segmentation.detect_sources):\n",
    "\n",
    "+ Full-width half-maximum (FWHM) of the typical source in the image, represented by`fwhm` in the code below. This is used to smooth the image before performing the segmentation.\n",
    "+ Threshold for a pixel to count as part of a source, typically expressed as a multiple of the standard deviation in the image and represented below by `threshold`.\n",
    "+ Number of adjacent pixels above the threshold to count as a source, represented by `npixels` below.\n",
    "+ Size of the kernel used for smoothing, represented by `kernel_size` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold and minimum object size\n",
    "threshold = 3. * std\n",
    "npixels = 10\n",
    "fwhm = 3\n",
    "kernel_size = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With those settings out of the way, there are three steps to the detection:\n",
    "\n",
    "1. Create the smoothing kernel.\n",
    "2. Apply the smoothing by convolving the kernel with the original image.\n",
    "3. Perform image segmentation on the convovled image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the kernel\n",
    "kernel = make_2dgaussian_kernel(fwhm, size=kernel_size)\n",
    "\n",
    "# Make a convolved image\n",
    "convolved_data = convolve(data_subtracted, kernel)\n",
    "\n",
    "# Create a segmentation image from the convolved image\n",
    "segm = detect_sources(convolved_data, threshold, npixels)\n",
    "\n",
    "print('Found {} sources'.format(segm.max_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 82 sources found here is the closest we have yet come to detecting all 100 sources that are in this image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why find peaks here??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original image, convolved image and segmentation image are shown below. Each color in the segmentation image represents a different source. The color map for this case is part of the [`SegmentationImage`](https://photutils.readthedocs.io/en/stable/api/photutils.segmentation.SegmentationImage.html#photutils.segmentation.SegmentationImage) generated by [`detect_sources`](https://photutils.readthedocs.io/en/stable/api/photutils.segmentation.detect_sources.html#photutils.segmentation.detect_sources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure with subplots\n",
    "fig, [ax1, ax2, ax3] = plt.subplots(3, 1, figsize=(6, 12))\n",
    "plt.tight_layout()\n",
    "\n",
    "# Plot the data\n",
    "# Set up the normalization and colormap\n",
    "norm_image = ImageNormalize(stretch=SqrtStretch())\n",
    "\n",
    "# Plot the original data\n",
    "fitsplot = ax1.imshow(data_subtracted,\n",
    "                      norm=norm_image, cmap='Greys_r')\n",
    "ax1.set_ylabel('Y (pixels)')\n",
    "ax1.set_title('Original Data')\n",
    "\n",
    "# Plot to convolved data\n",
    "convolved_plot = ax2.imshow(convolved_data, cmap=\"Greys_r\", norm=norm_image)\n",
    "ax2.set_ylabel(\"Y (pixel)\")\n",
    "ax2.set_title(\"Convolved image\")\n",
    "\n",
    "# Plot the segmentation image\n",
    "rand_cmap = make_random_cmap(seed=12345)\n",
    "rand_cmap.set_under('black')\n",
    "segplot = ax3.imshow(segm, vmin=1, cmap=segm.cmap)\n",
    "ax3.set_ylabel(\"Y (pixel)\")\n",
    "ax3.set_xlabel('X (pixels)')\n",
    "ax3.set_title('Segmentation Map')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much more information about the segmentation sources can be calculated using the [SourceCatalog](https://photutils.readthedocs.io/en/stable/api/photutils.segmentation.SourceCatalog.html#photutils.segmentation.SourceCatalog) from [`photutils`](https://photutils.readthedocs.io/en/stable/). This object will be discussed in more detail in the next notebook. For now we use it to construct apertures for source in the segmentation image that will be used when we compare image segmentation to the other source detection methods we have discussed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = SourceCatalog(data_subtracted, segm)\n",
    "table = catalog.to_table()\n",
    "\n",
    "# Define the approximate isophotal extent\n",
    "r = 4.  # pixels\n",
    "\n",
    "# Create the apertures\n",
    "apertures = []\n",
    "for obj in catalog:\n",
    "    position = (obj.xcentroid, obj.ycentroid)\n",
    "    a = obj.semimajor_sigma.value * r\n",
    "    b = obj.semiminor_sigma.value * r\n",
    "    theta = obj.orientation\n",
    "    apertures.append(EllipticalAperture(position, a, b, theta=theta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Detection Methods\n",
    "\n",
    "Let's compare how image segmentation compares to using [`DAOStarFinder`](https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html#photutils.detection.DAOStarFinder) and [`find_peaks`](https://photutils.readthedocs.io/en/stable/api/photutils.detection.find_peaks.html#photutils.detection.find_peaks) on this image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect sources with DAOFIND\n",
    "daofind = DAOStarFinder(fwhm=fwhm, threshold=threshold) \n",
    "sources_dao = daofind(data_subtracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect sources with find_peaks\n",
    "with warnings.catch_warnings(action=\"ignore\"):\n",
    "    sources_findpeaks = find_peaks(data_subtracted,\n",
    "                                   threshold=5. * std, box_size=29,\n",
    "                                   centroid_func=centroid_2dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''DAOStarFinder: {len(sources_dao)} sources\n",
    "find_peaks: {len(sources_findpeaks)} sources\n",
    "segmentation: {len(apertures)} sources''') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A graph of the source locations is helpful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1, 1, figsize=(8, 8))\n",
    "\n",
    "# Plot the data\n",
    "fitsplot = ax1.imshow(data, norm=norm_image, cmap='Greys_r', origin='lower')\n",
    "\n",
    "marker_size = 60\n",
    "ax1.scatter(sources_findpeaks['x_peak'], sources_findpeaks['y_peak'], s=marker_size, marker='s',\n",
    "            lw=1, alpha=1, facecolor='None', edgecolor='r', label='Found by find_peaks')\n",
    "ax1.scatter(sources_dao['xcentroid'], sources_dao['ycentroid'], s=2 * marker_size, marker='D',\n",
    "            lw=1, alpha=1, facecolor='None', edgecolor='#0077BB', label='Found by DAOfind')\n",
    "\n",
    "# Plot the apertures\n",
    "apertures[0].plot(color='cyan', lw=1, alpha=1, axes=ax1, label=\"Image segmentation\")\n",
    "for aperture in apertures[1:]:\n",
    "    aperture.plot(color='cyan', lw=1, alpha=1, axes=ax1)\n",
    "    \n",
    "# Add legend\n",
    "ax1.legend(ncol=3, loc='lower center', bbox_to_anchor=(0.5, -0.35))\n",
    "\n",
    "# Set the limits to avoid whitespace around the image\n",
    "ax1.set_xlim(0, 500)\n",
    "ax1.set_ylim(0, 250)\n",
    "\n",
    "ax1.set_xlabel('X (pixels)')\n",
    "ax1.set_ylabel('Y (pixels)')\n",
    "ax1.set_title('Sources Found by Different Methods');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Image segmentation identified more of the sources in this test image than either [`find_peaks`](https://photutils.readthedocs.io/en/stable/api/photutils.detection.find_peaks.html#photutils.detection.find_peaks) or [`DAOStarFinder`](https://photutils.readthedocs.io/en/stable/api/photutils.detection.DAOStarFinder.html#photutils.detection.DAOStarFinder). The latter wasn't expected to work well on this image because there is a large variety of source shapes and sizes. The undetected sources look relatively large and faint. Experimenting with the segmentation parameters would likely improve the detection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
