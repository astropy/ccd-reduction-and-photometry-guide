{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrate dark images\n",
    "\n",
    "Dark images, like any other images, need to be calibrated. Depending on the data\n",
    "you have and the choices you have made in reducing your data, the steps to\n",
    "reducing your images may include:\n",
    "\n",
    "1. Subtracting overscan (only if you decide to subtract overscan from all\n",
    "images).\n",
    "2. Trim the image (if it has overscan, whether you are using the overscan or\n",
    "not).\n",
    "3. Subtract bias (if you need to scale the calibrated dark frames to a different\n",
    "exposure time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from astropy.nddata import CCDData\n",
    "from ccdproc import ImageFileCollection\n",
    "import ccdproc as ccdp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Overscan subtracted, bias not removed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at what images you have\n",
    "\n",
    "First we gather up some information about the raw images and the reduced images\n",
    "up to this point. These examples have darks stored in a subdirectory of the\n",
    "folder with the rest of the images, so we create an `ImageFileCollection` for\n",
    "each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_path_raw = Path('example-cryo-LFC')\n",
    "\n",
    "ex1_images_raw = ImageFileCollection(ex1_path_raw)\n",
    "ex1_darks_raw = ImageFileCollection(ex1_path_raw / 'darks')\n",
    "\n",
    "ex1_path_reduced = Path('example1-reduced')\n",
    "ex1_images_reduced = ImageFileCollection(ex1_path_reduced)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw images, everything except the darks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_images_raw.summary['file', 'imagetyp', 'exptime', 'filter']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw dark frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_darks_raw.summary['file', 'imagetyp', 'exptime', 'filter']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide which calibration steps to take\n",
    "\n",
    "This example is, again, one of the chips of the LFC camera at Palomar. In\n",
    "earlier notebooks we have seen that the chip has a [useful overscan region](01-08-Overscan.ipynb#case-1-cryogenically-cooled-large-format-camera-lfc-at-palomar), has little dark current except for some hot pixels, and sensor glow in\n",
    "one corner of the chip.\n",
    "\n",
    "Looking at the list of non-dark images (i.e., the flat and light images) shows\n",
    "that for each exposure time in the non-dark images there is a set of dark\n",
    "exposures that has a matching, or very close to matching, exposure time.\n",
    "\n",
    "To be more explicit, there are flats with exposure times of 7.0 sec and 70.011\n",
    "sec and darks with exposure time of 7.0 and 70.0 sec. The dark and flat exposure\n",
    "times are close enough that there is no need to scale them.  The two images of\n",
    "an object are each roughly 300 sec, matching the darks with exposure time 300\n",
    "sec. The very small difference in exposure time, under 0.1 sec, does not need to\n",
    "be compensated for.\n",
    "\n",
    "Given this, we will:\n",
    "\n",
    "1. Subtract overscan from each of the darks. The useful overscan region is XXX\n",
    "(see LINK).\n",
    "2. Trim the overscan out of the dark images.\n",
    "\n",
    "We will *not* subtract bias from these images because we will *not* need to\n",
    "rescale them to a different exposure time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibrate the individual dark frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ccd, file_name in ex1_darks_raw.ccds(imagetyp='DARK',            # Just get the dark frames\n",
    "                                         ccd_kwargs={'unit': 'adu'}, # CCDData requires a unit for the image if \n",
    "                                                                     # it is not in the header\n",
    "                                         return_fname=True           # Provide the file name too.\n",
    "                                        ):    \n",
    "    # Subtract the overscan\n",
    "    ccd = ccdp.subtract_overscan(ccd, overscan=ccd[:, 2055:], median=True)\n",
    "    \n",
    "    # Trim the overscan\n",
    "    ccd = ccdp.trim_image(ccd[:, :2048])\n",
    "    \n",
    "    # Save the result\n",
    "    ccd.write(ex1_path_reduced / file_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduced images (so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex1_images_reduced.refresh()\n",
    "ex1_images_reduced.summary['file', 'imagetyp', 'exptime', 'filter', 'combined']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Overscan not subtracted, bias is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2_path_raw = Path('example-thermo-electric')\n",
    "\n",
    "ex2_images_raw = ImageFileCollection(ex2_path_raw)\n",
    "\n",
    "ex2_path_reduced = Path('example2-reduced')\n",
    "ex2_images_reduced = ImageFileCollection(ex2_path_reduced)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by looking at what exposure times we have in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex2_images_raw.summary['file', 'imagetyp', 'exposure'].show_in_notebook()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decide what steps to take next\n",
    "\n",
    "In this case the only dark frames have exposure time 90 sec. Though that matches\n",
    "the exposure time of the science images, the flat field images are much shorter\n",
    "exposure time, ranging from 1 sec to 1.21 sec. This type of range of exposure is\n",
    "typical when twilight flats are taken. Since these are a much different\n",
    "exposure time than the darks, the dark frames will need to be scaled.\n",
    "\n",
    "Recall that for this camera the overscan is not useful and should be\n",
    "trimmed off.\n",
    "\n",
    "Given this, we will:\n",
    "\n",
    "1. Trim the overscan from each of the dark frames.\n",
    "2. Subtract calibration bias from the dark frames so that we can scale the darks\n",
    "to a different exposure time."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration the individual dark frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we read the combined bias image created in the previous notebook. Though\n",
    "we could do this based on the file name, using a systematic set of header\n",
    "keywords to keep track of which images have been combined is less likely to lead\n",
    "to errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_bias = CCDData.read(ex2_images_reduced.files_filtered(imagetyp='bias', \n",
    "                                                               combined=True, \n",
    "                                                               include_path=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ccd, file_name in ex2_images_raw.ccds(imagetyp='DARK',            # Just get the bias frames\n",
    "                                          return_fname=True           # Provide the file name too.\n",
    "                                         ):\n",
    "        \n",
    "    # Trim the overscan\n",
    "    ccd = ccdp.trim_image(ccd[:, :4096])\n",
    "    \n",
    "    # Subtract bias\n",
    "    ccd = ccdp.subtract_bias(ccd, combined_bias)\n",
    "    # Save the result\n",
    "    ccd.write(ex2_path_reduced / file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
